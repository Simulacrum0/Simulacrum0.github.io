# LANGUAGE MATTERS

LANGUAGE_is_not_MEANING:

- Language and its words are the Tip of Iceberg in Meaning since what is NOT said, as in context, cultural-defaults and other assumptions, generally dwarfs what is expressed.

- "The body that is infected by a virus does not become infected because it understands the virus any more than the body that does not become infected misunderstands the virus. So a world in which everything—from bitmaps to blood—can be understood as a "form of speech" is also a world in which nothing actually is understood, a world in which what a speech act does is disconnected from what it means." : Michaels, The Shape of the Signifier

REPRESENTATION_MATTERS:
- So when you represent human languages, you have all the complications of what did somebody's language in that particular context. These complications are not just sarcasm or twists of emphasis but literally deciding that since someone said X it will mean Y, which is is subjective. So when we discuss meaning it is about how we store that meaning in a representation that is compact yet covers a myriad of  limitations, dependencies, and conditions.  I'm not aware of any language or symbolic system that is only about the computer's representation of meaning.  There are many ontology-approaches, such as OWL or RDF or Doug Lenat's CYC that do an admirable job of storing concepts and relationships for human consumption but not for 'machine-represenation' of 'what you want done, how, and potentially why'.

- So when we talk about 'Wantware meaning', it refers to 'what do I want to happen in software'. To capture this, we need a model that can capture a unified and scaleable form for 'what already exists in software'.

DIALOG:
- Thus PyDru is an approach of representing what you wanted. Effectively it's a dialog between 'what you said you wanted in your language/context' and 'what your wantware machine chose as the meaning'.  Dialog means iterating and its expected that wantware returns its assumptions, showing it back to you for you to say 'oh yes perfect' or 'nope make changes here, here and here'. The process can be understood as 'idealistically-staged' couples therapy between you and the computer to verify what the human is requesting and what the machine will represent and do.


PROGRAMS:
- Note that even the purity and specificity of programming languages with excellent standards, compilers, and feedback suffer from subjectitivy given compiler-optimizations, instruction-order-issues with chips, concurrent read/writes, and other aspects that can be lumped into conflicts or bugs.

MATH:
- Math represents just meaning.  The statement "1+1 = 2" means just that and generally, nothing more ( unless it acts as some metaphorical reference ). Math is one of the few examples of representing 'only meaning' but it doesn't represent all aspects of data and behavior. Math just represents math and a computer's representation of its meaning is limited by numerical-format or operation-result precision, chip-side-effects, and range issues ( we still can't even represent 0.1 in a 32bit IEEE float! ).

- Math is a wonderful way to represent meaning but it doesn't cover all the things you want to express for behavior nobody uses math to tell their employee or their kids or what to do. Humans relate data and 'instructions/caveats' with a range of language tools that remains ambiguous, contextual and cultural.


MEANING_MATTERS:
- Earlier i've written 'words matter' and while its true since words 'lead' to meaning, the most accurate phrase would be that your 'words lead to dialog-affirmed meaning'...and that meaning-matters as its used for all the choices made in generating/linking code representations of that meaning.


NLP_and_ESSENCE:
- Often when we discuss what we 'have' as IP, we get confused with NLP, as used in Google's BERT as used for the backend of chatbots.  While we use many technologies to match or predict patterns, such as NLP, our core IP is 'meaning units' which what stands behind all those text expressions.  Our meaning units let us select, configure & link code in realtime, whether i8 upsampling, object of interest encoding, surgical instrument recognition, or interface/behavior/simulation creation.

NLP_vs_MEANING:
- Natural Language Processing has improved greatly in the past few years given advances and adoption of machine learning methods. The ability to recognize or synthesize text offers many possibilities. Note that it works with text written in human or coding or domain-specialized languages. In all cases, languages express meaning as words, idioms, clauses, context and other schemes. NLP works with 'expressions' of meaning as 'text', never meaning itself.  The distinction is crucial as NLP works with similar or not-similar as its main pattern.  Which meanings are captured, which nuances or opposites are stored, is dependent on its training text...not actual meaning itself. Our meaning units *are* the actual 'meaning' not a reflection or simulacra of it.  We use NLP, we love NLP, and are excited for NLP's continuing advances as it helps us to initially guess as a user's intent from their text expressions. However we store 'meaning' so we can work with precisely-defined-in-computing-contexts-and-tolerances.  Meaning can and should be 'expressed' differently at different times for different audiences, interests, and needs.  Expressions of meaning, via language, code, art, and other streams of symbols are filters or 'level of detail operations' on meaning itself.